{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To Produce Small Data File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.append(\"./src\")\n",
    "import h5py\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from das_util import compute_misfit, get_tstamp\n",
    "from scipy.ndimage import gaussian_filter1d, gaussian_filter\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "\n",
    "data_dir='../../data_farm/data/'\n",
    "\n",
    "psd_data = os.path.join(data_dir, 'psd_all.hdf5')\n",
    "acf_data = os.path.join(data_dir, 'autocorr_15_60Hz.hdf5')\n",
    "acf_data_stretched = os.path.join(data_dir, 'autocorr_15_60Hz_stretched.hdf5')\n",
    "acf_data_stretchedx2 = os.path.join(data_dir, 'autocorr_15_60Hz_stretchedx2.hdf5')\n",
    "acf_data_stretchedx3 = os.path.join(data_dir, 'autocorr_15_60Hz_stretchedx3.hdf5')\n",
    "harper_met = os.path.join(data_dir, 'NewportSalop_merged.csv')\n",
    "reg_met = os.path.join(data_dir, 'met_newport.csv')\n",
    "spatial_data = os.path.join(data_dir, 'interp_dv_tillage_tire.csv')\n",
    "phy_data = os.path.join(data_dir, 'Soil_phy.csv')\n",
    "phy_data_interpolate = os.path.join(data_dir, 'interpolated_soil_phy.csv')\n",
    "\n",
    "freqmin=25\n",
    "freqmax=50\n",
    "samp_freq = 500\n",
    "dchan = 3.19"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ACFs (H5)\n",
    "Raw, strected, stretchedx2, stretchedx3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Read big h5 files\n",
    "with h5py.File(acf_data, 'r') as f:\n",
    "    corr_all_time_ch18 = f['autocorr'][18, :, 2500:3000, 0]\n",
    "    corr_all_time_ch33 = f['autocorr'][33, :, 2500:3000, 0]\n",
    "    corr_all_time_ch44 = f['autocorr'][44, :, 2500:3000, 0]\n",
    "    corr_all_channel_30_40min = f['autocorr'][:50, 30:40, 2500:2700, 0]\n",
    "with h5py.File(acf_data_stretched, 'r') as f:\n",
    "    corr_all_time_stretched1_ch18 = f['autocorr'][18, :, :500]\n",
    "    corr_all_time_stretched1_ch33 = f['autocorr'][33, :, :500]\n",
    "    corr_all_time_stretched1_ch44 = f['autocorr'][44, :, :500]\n",
    "with h5py.File(acf_data_stretchedx2, 'r') as f:\n",
    "    corr_all_time_stretched2_ch18 = f['autocorr'][18, :, :500]\n",
    "    corr_all_time_stretched2_ch33 = f['autocorr'][33, :, :500]\n",
    "    corr_all_time_stretched2_ch44 = f['autocorr'][44, :, :500]\n",
    "with h5py.File(acf_data_stretchedx3, 'r') as f:\n",
    "    corr_all_time_stretched3_ch18 = f['autocorr'][18, :, :500]\n",
    "    corr_all_time_stretched3_ch33 = f['autocorr'][33, :, :500]\n",
    "    corr_all_time_stretched3_ch44 = f['autocorr'][44, :, :500]\n",
    "\n",
    "### Save small h5 files\n",
    "with h5py.File(os.path.join(data_dir, 'autocorr_15_60Hz_3chs500pts.hdf5'), 'w') as f:\n",
    "    f.create_dataset('corr_all_time_ch18', data=corr_all_time_ch18)\n",
    "    f.create_dataset('corr_all_time_ch33', data=corr_all_time_ch33)\n",
    "    f.create_dataset('corr_all_time_ch44', data=corr_all_time_ch44)\n",
    "    f.create_dataset('corr_all_time_stretched1_ch18', data=corr_all_time_stretched1_ch18)\n",
    "    f.create_dataset('corr_all_time_stretched1_ch33', data=corr_all_time_stretched1_ch33)\n",
    "    f.create_dataset('corr_all_time_stretched1_ch44', data=corr_all_time_stretched1_ch44)\n",
    "    f.create_dataset('corr_all_time_stretched2_ch18', data=corr_all_time_stretched2_ch18)\n",
    "    f.create_dataset('corr_all_time_stretched2_ch33', data=corr_all_time_stretched2_ch33)\n",
    "    f.create_dataset('corr_all_time_stretched2_ch44', data=corr_all_time_stretched2_ch44)\n",
    "    f.create_dataset('corr_all_time_stretched3_ch18', data=corr_all_time_stretched3_ch18)\n",
    "    f.create_dataset('corr_all_time_stretched3_ch33', data=corr_all_time_stretched3_ch33)\n",
    "    f.create_dataset('corr_all_time_stretched3_ch44', data=corr_all_time_stretched3_ch44)\n",
    "\n",
    "with h5py.File(os.path.join(data_dir, 'autocorr_15_60Hz_30_40min.hdf5'), 'w') as f:\n",
    "    f.create_dataset('corr_all_channel_30_40min', data=corr_all_channel_30_40min)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## dVV (H5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Iteration 1\n",
    "with h5py.File(os.path.join(data_dir, 'final_peaks_interp_smooth_15_60Hz.h5'), 'r') as f:\n",
    "    stretch_ratio = f['final_peaks'][:]\n",
    "\n",
    "## de ratio using the humidist time period\n",
    "deratio_dvv = stretch_ratio / np.repeat(np.mean(stretch_ratio[:, 269:280], axis=1)[:, np.newaxis], 482, axis=1) - 1\n",
    "\n",
    "with h5py.File(os.path.join(data_dir, 'final_peaks_deRatio.h5'), 'w') as f:\n",
    "    f.create_dataset('deratio_dvv', data=deratio_dvv)\n",
    "\n",
    "\n",
    "### Iteration 2\n",
    "with h5py.File(os.path.join(data_dir, 'final_peaks_15_60Hz_2nd_iteration.h5'), 'r') as f:\n",
    "    stretch_ratio = f['final_peaks'][:50]\n",
    "stretch_ratio[stretch_ratio<0.75] = 0.75\n",
    "\n",
    "## de ratio using the humidist time period\n",
    "stretch_ratio = stretch_ratio / np.repeat(np.mean(stretch_ratio[:, 269:280], axis=1)[:, np.newaxis], 482, axis=1)\n",
    "\n",
    "stretch_ratio[np.isnan(stretch_ratio)] = 1\n",
    "\n",
    "deratio_dvv = (deratio_dvv + 1) * stretch_ratio - 1\n",
    "\n",
    "with h5py.File(os.path.join(data_dir, 'final_peaks_deRatio_2iterations.h5'), 'w') as f:\n",
    "    f.create_dataset('deratio_dvv', data=deratio_dvv)\n",
    "\n",
    "\n",
    "### Iteration 3\n",
    "with h5py.File(os.path.join(data_dir, 'final_peaks_15_60Hz_3rd_iteration.h5'), 'r') as f:\n",
    "    stretch_ratio = f['final_peaks'][:50]-0.1\n",
    "\n",
    "## de ratio using the humidist time period\n",
    "stretch_ratio = stretch_ratio / np.repeat(np.mean(stretch_ratio[:, 269:280], axis=1)[:, np.newaxis], 482, axis=1)\n",
    "\n",
    "stretch_ratio[np.isnan(stretch_ratio)] = 1\n",
    "\n",
    "deratio_dvv = (deratio_dvv + 1) * stretch_ratio - 1\n",
    "\n",
    "with h5py.File(os.path.join(data_dir, 'final_peaks_deRatio_3iterations.h5'), 'w') as f:\n",
    "    f.create_dataset('deratio_dvv', data=deratio_dvv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stretched ACFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_ratio = deratio_dvv + 1\n",
    "\n",
    "# shape_3d = (corr_all_time.shape[0], corr_all_time.shape[1], int(corr_all_time.shape[2]*all_ratio.max())+1)\n",
    "# corr_all_time_stretched =  np.zeros(shape_3d, dtype=np.float32)\n",
    "\n",
    "# for iloc in range(50):\n",
    "#     for itime in range(482):\n",
    "#         ratio = all_ratio[iloc, itime]\n",
    "#         tmp = zoom(corr_all_time[iloc, itime], ratio, order=1)\n",
    "#         corr_all_time_stretched[iloc, itime, :len(tmp)] = tmp \n",
    "    \n",
    "    # plt.figure(figsize = (12, 5))\n",
    "    # plt.imshow(corr_all_time_stretched[iloc, :, :500].T, aspect='auto', vmin=-0.2, vmax=0.2, cmap='RdBu', origin='lower')\n",
    "\n",
    "    # plt.xlabel(\"ACF time (x 5 minutes)\", fontsize = 16)\n",
    "    # plt.ylabel(\"Time lag (sec)\", fontsize = 16)\n",
    "    # bar = plt.colorbar()\n",
    "    # bar.set_label('Auto-correlation Coefficient', fontsize = 15)\n",
    "\n",
    "### stack strected ACF for a static GF\n",
    "# mean_acf = np.mean(corr_all_time_stretched, axis=1)\n",
    "\n",
    "\n",
    "# ### Save the stretched ACF\n",
    "# with h5py.File('data/autocorr_15_60Hz_stretchedx3.hdf5', 'w') as f:\n",
    "#     f.create_dataset('autocorr', data=corr_all_time_stretched)\n",
    "#     f.create_dataset('mean_acf', data=mean_acf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "quakeflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
