{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53573f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\".\")\n",
    "sys.path.append(\"noisepy4das_repo/NoisePy4DAS-SeaDAS/src\")\n",
    "sys.path.append(\"noisepy4das_repo/NoisePy4DAS-SeaDAS/DASstore\")\n",
    "import cv2\n",
    "import os\n",
    "import gc\n",
    "import h5py\n",
    "import math\n",
    "import time\n",
    "import DAS_module\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import scipy.signal as sgn\n",
    "\n",
    "from tqdm import tqdm\n",
    "from obspy import UTCDateTime\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "from functools import partial\n",
    "from scipy.signal import butter\n",
    "from scipy.signal import detrend\n",
    "from scipy.signal import decimate\n",
    "from scipy.signal import filtfilt\n",
    "from scipy.signal import spectrogram\n",
    "from scipy.interpolate import interp1d\n",
    "from dasstore.zarr import Client\n",
    "from multiprocessing import Pool\n",
    "from matplotlib import pyplot as plt\n",
    "from das_util import read_decimate, get_tstamp, calc_NFFT\n",
    "from das_util import next_power_of_2\n",
    "\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams.update({'font.size': 16})\n",
    "os.environ[\"HDF5_USE_FILE_LOCKING\"] = \"FALSE\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2843ad3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fk_filter_2cones(vsp, w1=0, w2=0, cone1=False, cone2=False):\n",
    "    n1, n2 = vsp.shape\n",
    "    nf = next_power_of_2(n1)\n",
    "    nk = next_power_of_2(n2)\n",
    "\n",
    "    nf2=int(nf/2)\n",
    "    nk2=int(nk/2)\n",
    "    \n",
    "    fk2d = np.fft.fft2(vsp, s=(nf,nk))\n",
    "    fk2d = np.fft.fftshift(fk2d, axes=(-2,-1))\n",
    "    \n",
    "    nw1 = int(np.ceil(w1*nk))\n",
    "    nw2 = int(np.ceil(w2*nf))\n",
    "\n",
    "    mask1=np.ones((nf,nk), dtype=np.float64)\n",
    "    mask2=np.ones((nf,nk), dtype=np.float64)\n",
    "\n",
    "    if cone1:\n",
    "        for j in np.arange(nk2-nw1, nk2+1):\n",
    "            th1 = int((j-nk2+nw1) * nf2/nw1)\n",
    "\n",
    "            mask1[:th1, j] = 0\n",
    "            mask1[nf-th1:, j] = 0\n",
    "            mask1[:th1, nk-j] = 0\n",
    "            mask1[nf-th1:, nk-j] = 0\n",
    "\n",
    "    if cone2:\n",
    "        for j in np.arange(0, nk2):\n",
    "            th2 = int(nf2 - (nw2/nk2)*(nk2-j))\n",
    "            mask2[th2:nf-th2+1, j] = 0\n",
    "            if j != 0:\n",
    "                mask2[th2:nf-th2+1, nk-j] = 0\n",
    "\n",
    "\n",
    "    mask = mask2*mask1\n",
    "    \n",
    "    filtered_2d = fk2d * mask\n",
    "    tmp = np.fft.ifftshift(filtered_2d)\n",
    "    output = np.fft.ifft2(tmp, s=(nk,nf), axes=(-1, -2))\n",
    "    \n",
    "    return output[:n1,:n2], filtered_2d, fk2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4eb130",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch(wave1, wave2, time, maxshift=0, max_ratio=2):\n",
    "\n",
    "    interp_f = interp1d(time, wave2, bounds_error=False, fill_value=0.)\n",
    "    n1 = np.sum(np.square(wave1))\n",
    "    dt = time[1] - time[0]\n",
    "    cc = 0\n",
    "    relative_ratio = 1\n",
    "    npts = len(time)\n",
    "\n",
    "    for ratio in np.arange(1/max_ratio, max_ratio, 0.01):\n",
    "        dt_new = dt / ratio\n",
    "        time_new = np.arange(time[0], time[-1], dt_new)\n",
    "        wave_new = interp_f(time_new)\n",
    "        \n",
    "        n2 = np.sum(np.square(wave_new))\n",
    "        corr = sgn.correlate(wave1, wave_new) / np.sqrt(n1 * n2)\n",
    "\n",
    "        l_maxshift = min(len(wave_new), maxshift)\n",
    "        r_maxshift = min(len(wave1), maxshift)\n",
    "\n",
    "        st_pt = len(wave_new) - l_maxshift\n",
    "        en_pt = len(wave_new) + r_maxshift+1\n",
    "\n",
    "        cc_best = np.nanmax(corr[st_pt: en_pt])\n",
    "\n",
    "        if cc < cc_best:\n",
    "            cc = cc_best\n",
    "            relative_ratio = ratio\n",
    "\n",
    "    dt_new = dt / relative_ratio\n",
    "    time_new = np.arange(time[0], time[-1], dt_new)\n",
    "    wave_new = interp_f(time_new)\n",
    "    \n",
    "    \n",
    "    return wave_new, np.arange(len(wave_new))*dt, relative_ratio, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f4fcd46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stretch_distribution(wave1, wave2, time, maxshift=0, max_ratio=2):\n",
    "\n",
    "    stretch_range = np.arange(1/max_ratio, max_ratio, 0.01)\n",
    "    \n",
    "    interp_f = interp1d(time, wave2, bounds_error=False, fill_value=0.)\n",
    "    n1 = np.sum(np.square(wave1))\n",
    "    dt = time[1] - time[0]\n",
    "    cc = np.zeros(len(stretch_range), dtype = np.float32)\n",
    "    npts = len(time)\n",
    "\n",
    "    for i, ratio in enumerate(stretch_range):\n",
    "        dt_new = dt / ratio\n",
    "        time_new = np.arange(time[0], time[-1], dt_new)\n",
    "        wave_new = interp_f(time_new)\n",
    "        \n",
    "        n2 = np.sum(np.square(wave_new))\n",
    "        corr = sgn.correlate(wave1, wave_new) / np.sqrt(n1 * n2)\n",
    "\n",
    "        l_maxshift = min(len(wave_new), maxshift)\n",
    "        r_maxshift = min(len(wave1), maxshift)\n",
    "\n",
    "        st_pt = len(wave_new) - l_maxshift\n",
    "        en_pt = len(wave_new) + r_maxshift+1\n",
    "\n",
    "        cc[i] = np.nanmax(corr[st_pt: en_pt])\n",
    "    \n",
    "    return stretch_range, cc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bced1290",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = '/1-fnp/petasaur/p-wd05/harper_plots'\n",
    "file_list = np.array(os.listdir(data_dir))\n",
    "\n",
    "acqu_time = np.array([get_tstamp(i) for i in file_list])\n",
    "new_index = np.argsort(np.array(acqu_time)-acqu_time[0])\n",
    "acqu_time = acqu_time[new_index]\n",
    "\n",
    "file_list = file_list[new_index]\n",
    "file_path = [os.path.join(data_dir,i) for i in file_list]\n",
    "\n",
    "# %% reasonable acquisition time period\n",
    "list_all = np.arange(28,2468)\n",
    "num_sample_all = np.zeros(len(list_all), dtype=np.float64)\n",
    "sample_rate_all = np.zeros(len(list_all), dtype=np.float64)\n",
    "delta_space_all = np.zeros(len(list_all), dtype=np.float64)\n",
    "for i,j in enumerate(list_all):\n",
    "    with h5py.File(file_path[j],'r') as f:      \n",
    "        num_sample_all[i]  = len(f['Acquisition']['Raw[0]']['RawDataTime'][:])\n",
    "        sample_rate_all[i] = f['Acquisition']['Raw[0]'].attrs['OutputDataRate']\n",
    "        delta_space_all[i] = f['Acquisition'].attrs['SpatialSamplingInterval']\n",
    "        \n",
    "# %% exclude files that dropped samples\n",
    "ind_good = np.where(num_sample_all == 120000)[0]\n",
    "list_all = list_all[ind_good]\n",
    "delta_space = delta_space_all[ind_good][0]\n",
    "num_sample = num_sample_all[ind_good][0]\n",
    "sample_rate = sample_rate_all[ind_good][0]\n",
    "delta_time = 1.0 / sample_rate\n",
    "\n",
    "print(f'good acqusition for {len(ind_good)} minutes')\n",
    "\n",
    "del num_sample_all, file_path\n",
    "gc.collect()\n",
    "# %% See if the acquisition time is continuous\n",
    "file_list = file_list[list_all]\n",
    "acqu_time = acqu_time[list_all]\n",
    "file_path = [os.path.join(data_dir,i) for i in file_list]\n",
    "plt.close('all')\n",
    "fig, ax = plt.subplots(1, 1, figsize=(13, 2.5), constrained_layout=True)\n",
    "ax.scatter(list_all, acqu_time.astype('datetime64[m]'), marker='o', s=0.1, edgecolors='k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffda0ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_file = np.arange(0, len(acqu_time), 5)\n",
    "time_stamps = acqu_time[start_file]\n",
    "\n",
    "samp_freq = 500                # targeted sampling rate\n",
    "freq_norm   = 'no'             # 'no' for no whitening, or 'rma' for running-mean average, 'phase_only' for sign-bit normalization in freq domain.\n",
    "time_norm   = 'one_bit'        # 'no' for no normalization, or 'rma', 'one_bit' for normalization in time domain\n",
    "cc_method   = 'xcorr'          # 'xcorr' for pure cross correlation, 'deconv' for deconvolution; FOR \"COHERENCY\" PLEASE set freq_norm to \"rma\", time_norm to \"no\" and cc_method to \"xcorr\"\n",
    "smooth_N    = 50               # moving window length for time domain normalization if selected (points)\n",
    "smoothspect_N  = 50            # moving window length to smooth spectrum amplitude (points)\n",
    "maxlag      = 5                # lags of cross-correlation to save (sec)\n",
    "\n",
    "# criteria for data selection\n",
    "max_over_std = 10 *9              # threshold to remove window of bad signals: set it to 10*9 if prefer not to remove them\n",
    "num_sample = 30000\n",
    "cc_len = delta_time * num_sample  # correlate length in second\n",
    "step   = delta_time * num_sample  # stepping length in second\n",
    "\n",
    "n_pair = 1\n",
    "n_lag = maxlag * samp_freq * 2 + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0dbbb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/fd1/QibinShi_data/England_farm/psd_all_channel.hdf5', 'r') as f:\n",
    "    PSD_all_time = f['psd_all_time'][:]\n",
    "    freq = f['frequency'][:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a25bc82",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "hourly_index=[67,127,187,247,299,359,419,466,526,586,646,706,766,826,886,946,1003,1063,1123,\n",
    "         1183,1243,1302,1362,1422,1482,1542,1599,1659,1719,1779,1839,1899,1959,2019,\n",
    "         2078,2138,2198,2258,2318]\n",
    "# for i in hourly_index:\n",
    "#     print(acqu_time[i])\n",
    "\n",
    "csv_file = pd.read_csv('NewportSalop_merged.csv', low_memory=False)\n",
    "j = 32\n",
    "# print(csv_file['Time'][j:j+40])\n",
    "rainfall=csv_file[' Rainfall Total since 0900'][j:j+40].to_numpy()\n",
    "rain_diff=np.diff(rainfall)\n",
    "# rain_diff=rain_diff / np.max(rain_diff)\n",
    "\n",
    "soil_temp_10=csv_file[' 10cm Soil Temperature'][j+1:j+40].to_numpy()\n",
    "soil_temp_30=csv_file['30cm Soil Temperature'][j+1:j+40].to_numpy()\n",
    "soil_temp_100=csv_file['100cm Soil Temperature'][j+1:j+40].to_numpy()\n",
    "humidity=csv_file['Humidity'][j+1:j+40].to_numpy()\n",
    "\n",
    "# for i in range(PSD_all_channel.shape[0]):\n",
    "#     ave_psd=np.sum(PSD_all_channel[i, :, 52:90], axis=-1)\n",
    "#     ave_psd=ave_psd / np.max(ave_psd)\n",
    "#     ## smoothing over 1 hr window\n",
    "#     hr_psd=[]\n",
    "#     for ind in hourly_index:\n",
    "#         st_ind = int(ind - 60)\n",
    "#         ed_ind = st_ind + 60\n",
    "#         psd_int=np.sum(ave_psd[st_ind:ed_ind])\n",
    "\n",
    "#         hr_psd.append(psd_int)\n",
    "\n",
    "#     hr_psd = hr_psd / max(hr_psd)\n",
    "#     plt.figure(figsize = (12, 4), dpi = 200)   \n",
    "#     plt.scatter(hourly_index, rain_diff/3.5, label='1 hr rain', color='g', marker='o', s=100)\n",
    "#     plt.scatter(hourly_index, np.array(hr_psd), label='1 hr psd', color='b', marker='*', s=100)\n",
    "#     plt.plot(hourly_index, np.array(hr_psd))\n",
    "#     plt.plot(np.arange(ave_psd.shape[-1]), ave_psd, label='psd')\n",
    "#     # plt.xticks(np.arange(0, data_plot.shape[1],100), xhrs[:data_plot.shape[1]:100], fontsize = 12)\n",
    "\n",
    "#     plt.xlabel(\"ACF time (min)\", fontsize = 16)\n",
    "#     plt.ylabel(\"Sum of PSD\", fontsize = 16)\n",
    "#     plt.title('Channel ' + str(i+44), fontsize = 20)  \n",
    "#     plt.ylim(-0.2, 1.2)\n",
    "#     plt.legend()\n",
    "\n",
    "ave_psd=np.mean(np.sum(PSD_all_time[0:44, :, 52:90], axis=-1) * (freq[1]-freq[0]), axis=0)\n",
    "# ave_psd=ave_psd / np.max(ave_psd)\n",
    "## smoothing over 1 hr window\n",
    "hr_psd=[]\n",
    "for ind in hourly_index:\n",
    "    st_ind = int(ind - 60)\n",
    "    ed_ind = st_ind + 60\n",
    "    psd_int=np.sum(ave_psd[st_ind:ed_ind])\n",
    "\n",
    "    hr_psd.append(psd_int)\n",
    "\n",
    "# hr_psd = hr_psd / max(hr_psd)\n",
    "\n",
    "xax=np.arange(0, ave_psd.shape[-1], 240)\n",
    "tax=acqu_time[:ave_psd.shape[-1]:240]\n",
    "hrax=[dt.strftime('%d %H:%M') for dt in tax]\n",
    "plt.figure(figsize = (12, 4), dpi = 200)   \n",
    "plt.scatter(hourly_index, rain_diff/3.5, label='1-hour rainfall / 3.5', color='g', marker='o', s=100)\n",
    "plt.scatter(hourly_index, np.array(hr_psd), label='1-hour PSD', color='b', marker='*', s=100)\n",
    "plt.plot(hourly_index, np.array(hr_psd))\n",
    "plt.plot(np.arange(ave_psd.shape[-1]), ave_psd, label='1-minute PSD')\n",
    "plt.xticks(xax, hrax, fontsize = 12)\n",
    "plt.xlabel(\"Time\", fontsize = 16)\n",
    "plt.ylabel(\"Sum of PSD\", fontsize = 16)\n",
    "plt.title('Averaged PSD of the SW central channels ', fontsize = 20)  \n",
    "plt.ylim(-0.2, 1.8)\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File('/fd1/QibinShi_data/England_farm/autocorr_25_50Hz.hdf5', 'r') as f:\n",
    "    corr_all_time = f['autocorr'][:, :, 2500:2650, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5f8603",
   "metadata": {},
   "outputs": [],
   "source": [
    "win_st = int(0.012*samp_freq)\n",
    "\n",
    "with h5py.File('/fd1/QibinShi_data/England_farm/autocorr_25_50Hz.hdf5', 'r') as f:\n",
    "    corr_all_time = f['autocorr'][:, :, 2500:2650, 0]\n",
    "    \n",
    "for iloc in range(51):\n",
    "    data_plot=corr_all_time[iloc].T\n",
    "    x=np.arange(data_plot.shape[1])\n",
    "    y=np.arange(data_plot.shape[0])\n",
    "    xts=np.array(time_stamps)\n",
    "    xhrs=np.round((xts - xts[0]).astype('float')/3600, 2)\n",
    "    plt.figure(figsize = (10, 3), dpi = 200)\n",
    "    for i in x[::5]:\n",
    "        plt.plot(y/samp_freq, data_plot[:,i])\n",
    "\n",
    "    plt.plot(y/samp_freq, np.mean(data_plot, axis=1), c='k', lw=9, alpha=0.3, label='mean of all')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.title('channel '+ str(iloc+44))\n",
    "    plt.xlabel('lag time (s)')\n",
    "    plt.axvline(x=win_st/samp_freq, color='k', linestyle='--', label='1st reflection')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e26e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "time = y[win_st:] / samp_freq\n",
    "stack_stretch=np.zeros((51, len(time)), dtype = np.float32)\n",
    "for iloc in range(51):\n",
    "    data_plot=corr_all_time[iloc].T\n",
    "    x=np.arange(data_plot.shape[1])\n",
    "    y=np.arange(data_plot.shape[0])\n",
    "    trunc_acf = data_plot[win_st:, :]\n",
    "    trunc_stk = np.mean(trunc_acf, axis=1)\n",
    "    \n",
    "    count = 0\n",
    "    plt.figure(figsize = (10, 3), dpi = 200)\n",
    "    for i in x[::5]:\n",
    "        tmp=np.zeros_like(time)\n",
    "        stretched, time_new, ratio, cc = stretch(trunc_stk, trunc_acf[:,i], time, max_ratio=2)\n",
    "        if cc > 0.5:\n",
    "            length=min(len(stretched), len(time))\n",
    "            tmp[:length]=stretched[:length]\n",
    "            stack_stretch[iloc, :] += tmp\n",
    "            plt.plot(time, tmp)\n",
    "            count +=1\n",
    "        else:continue\n",
    "    plt.plot(time, stack_stretch[iloc, :]/count, c='k', lw=9, alpha=0.5, label='mean of all')\n",
    "    plt.title('channel '+ str(iloc+44)); plt.legend(); plt.xlabel('lag time (s)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb084cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqmin=25\n",
    "freqmax=freqmin*2\n",
    "# Stretch again to get distribution\n",
    "stretch_range = np.arange(1/2, 2, 0.01)\n",
    "all_ratio = np.zeros((51, len(stretch_range), len(x)), dtype = np.float32)\n",
    "all_cc = np.zeros((51, len(stretch_range), len(x)), dtype = np.float32)\n",
    "\n",
    "xax=np.arange(0, x.shape[-1], 48)\n",
    "tax=acqu_time[:2410:240]\n",
    "\n",
    "for iloc in [8]:\n",
    "    data_plot=corr_all_time[iloc].T\n",
    "    trunc_acf = data_plot[win_st:, :]\n",
    "    trunc_stk = stack_stretch[iloc, :]/count\n",
    "    strecthed_acfs = np.zeros_like(trunc_acf)\n",
    "    for i in x:\n",
    "        ratios, ccs = stretch_distribution(trunc_stk, trunc_acf[:,i], time, max_ratio=2)\n",
    "        all_cc[iloc, :, i] = ccs  \n",
    "    plt.figure(figsize = (16, 4), dpi = 300)\n",
    "    plt.pcolormesh(x, stretch_range-1, all_cc[iloc], shading='auto', vmin=0.2, vmax=1, cmap = 'hot')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    plt.xlabel(\"ACF time (hour)\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "    plt.ylim(-0.5, 0.6)\n",
    "    plt.title('channel '+ str(iloc+44)+ '_' + str(freqmin)+'_'+str(freqmax)+'Hz', fontsize = 20)\n",
    "    bar = plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    \n",
    "    axcopy = plt.twinx()\n",
    "#     axcopy.scatter(np.array(hourly_index)/5, soil_temp_10-7.5, label='T_10cm', color='w', marker='^')\n",
    "#     axcopy.scatter(np.array(hourly_index)/5, (soil_temp_30-7.5), label='T_30cm', color='w', marker='s')\n",
    "#     axcopy.scatter(np.array(hourly_index)/5, (soil_temp_100-7.5), label='T_100cm', color='w', marker='v')\n",
    "    axcopy.scatter(np.array(hourly_index)/5, (110-humidity)/250, label='(110-RH) / 250', color='cyan', marker='P', s=100)\n",
    "#     axcopy.scatter(np.array(hourly_index)/5, rain_diff/3.5, label='1-hour rainfall', color='g', marker='o', s=100)\n",
    "#     axcopy.scatter(np.array(hourly_index)/5, np.array(hr_psd), label='1-hour PSD', color='b', marker='*', s=100)\n",
    "#     axcopy.plot(np.array(hourly_index)/5, np.array(hr_psd))\n",
    "    axcopy.plot(np.arange(ave_psd.shape[-1])/5, ave_psd, label='1-minute PSD', color='w')\n",
    "    axcopy.legend(fontsize = 7)\n",
    "    axcopy.set_ylim(-0.02,0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8701cc",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Stretch again to get distribution\n",
    "stretch_range = np.arange(1/2, 2, 0.01)\n",
    "all_ratio = np.zeros((51, len(stretch_range), len(x)), dtype = np.float32)\n",
    "all_cc = np.zeros((51, len(stretch_range), len(x)), dtype = np.float32)\n",
    "\n",
    "xax=np.arange(0, x.shape[-1], 48)\n",
    "tax=acqu_time[:2410:240]\n",
    "\n",
    "# for iloc in [18,30]:\n",
    "for iloc in range(51):\n",
    "    data_plot=corr_all_time[iloc].T\n",
    "    trunc_acf = data_plot[win_st:, :]\n",
    "    trunc_stk = stack_stretch[iloc, :]/count\n",
    "    strecthed_acfs = np.zeros_like(trunc_acf)\n",
    "    for i in x:\n",
    "        ratios, ccs = stretch_distribution(trunc_stk, trunc_acf[:,i], time, max_ratio=2)\n",
    "        all_cc[iloc, :, i] = ccs \n",
    "        \n",
    "    ######################\n",
    "    ## FK filter\n",
    "    # %% Use cone-filter\n",
    "    filt_data, filtered_fk, fk2d = fk_filter_2cones(all_cc[iloc].T, w1=0.03, w2=0.005, cone1=True, cone2=False)\n",
    "\n",
    "#     plt.figure(figsize=(18, 5))\n",
    "#     plt.imshow(filt_data.real.T, aspect = 'auto', cmap = 'hot', vmax = 0.2, vmin = 1, origin='lower')\n",
    "#     plt.title('Mask filter after 2D Fourier Transform')\n",
    "#     plt.colorbar()\n",
    "\n",
    "#     ## verify the FK mask\n",
    "#     plt.figure(figsize=(18, 5), dpi=300)\n",
    "#     plt.imshow(np.log10(np.abs(filtered_fk)), aspect='auto', cmap='RdBu', origin='lower')\n",
    "#     plt.colorbar()\n",
    "#     plt.figure(figsize=(18, 5), dpi=300)\n",
    "#     plt.imshow(np.log10(np.abs(fk2d)), aspect='auto', cmap='RdBu', origin='lower')\n",
    "#     plt.colorbar()\n",
    "    #######################\n",
    "    image = filt_data.real.T[:,:,np.newaxis]*200\n",
    "    image = image - np.nanmin(image)\n",
    "    denoised_image = cv2.medianBlur(image.astype(np.uint8), 7)/256\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.pcolormesh(x, stretch_range-1, denoised_image, shading='auto', vmin=0.3, vmax=0.8, cmap = 'hot')\n",
    "    plt.title('median filter in 2D_iloc' + str(iloc))\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "    #######################\n",
    "#     kernel_size_x = 2\n",
    "#     denoised_image_x = np.zeros_like(denoised_image)\n",
    "#     for i in range(image.shape[1]):\n",
    "#         denoised_image_x[:, i] = np.median(image[:, i - kernel_size_x:i + kernel_size_x + 1, 0], axis=1)\n",
    "   \n",
    "#     plt.figure(figsize=(18, 5))\n",
    "#     plt.imshow(denoised_image_x, aspect = 'auto', cmap = 'hot', vmax=200, vmin=80, origin='lower')\n",
    "#     plt.title('median filter along X')\n",
    "#     plt.colorbar()\n",
    "    #######################\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    dvv_ind = np.argmax(denoised_image, axis=0)\n",
    "    dvv = np.zeros(len(dvv_ind), dtype=np.float32)\n",
    "    for i in range(len(dvv_ind)):\n",
    "        dvv[i]= stretch_range[dvv_ind[i]]\n",
    "    cc_dvv = np.nanmax(denoised_image, axis=0)\n",
    "    plt.scatter(x, dvv-np.mean(dvv), cmap='viridis', c=cc_dvv, s=40, marker='o')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    plt.title('dVV after denoising')\n",
    "    plt.ylim(-0.6, 0.6)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "    \n",
    "    # Save all stretch ratio and CC\n",
    "    with h5py.File('dvv_stretch_cc_25_50Hz.hdf5', 'r') as f:\n",
    "        ratio_all = f['ratio'][:]\n",
    "        cc_all = f['cc'][:]\n",
    "    plt.figure(figsize = (18, 5))\n",
    "    plt.scatter(x, ratio_all[iloc]-np.mean(ratio_all[iloc]), cmap='viridis', c=np.array(cc_all[iloc]), s=40, marker='o')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    plt.title('dVV raw')\n",
    "    plt.ylim(-0.6, 0.6)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15a4fc6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Stretch again to get distribution\n",
    "stretch_range = np.arange(1/2, 2, 0.01)\n",
    "all_ratio = np.zeros((51, len(stretch_range), len(x)), dtype = np.float32)\n",
    "all_cc = np.zeros((51, len(stretch_range), len(x)), dtype = np.float32)\n",
    "\n",
    "xax=np.arange(0, x.shape[-1], 48)\n",
    "tax=acqu_time[:2410:240]\n",
    "\n",
    "for iloc in [8, 18, 30]:\n",
    "# for iloc in range(51):\n",
    "    data_plot=corr_all_time[iloc].T\n",
    "    trunc_acf = data_plot[win_st:, :]\n",
    "    trunc_stk = stack_stretch[iloc, :]/count\n",
    "    strecthed_acfs = np.zeros_like(trunc_acf)\n",
    "    for i in x:\n",
    "        ratios, ccs = stretch_distribution(trunc_stk, trunc_acf[:,i], time, max_ratio=2)\n",
    "        all_cc[iloc, :, i] = ccs \n",
    "        \n",
    "    ######################\n",
    "    ## FK filter\n",
    "    # %% Use cone-filter\n",
    "    filt_data, filtered_fk, fk2d = fk_filter_2cones(all_cc[iloc].T, w1=0.015, w2=0.005, cone1=True, cone2=False)\n",
    "\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.pcolormesh(x, stretch_range-1, filt_data.real.T, shading='auto', vmin=0.2, vmax=1, cmap = 'hot')\n",
    "    plt.title('Mask filter after 2D Fourier Transform')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "\n",
    "    ## verify the FK mask\n",
    "    plt.figure(figsize=(18, 5), dpi=300)\n",
    "    plt.imshow(np.log10(np.abs(filtered_fk)), aspect='auto', cmap='RdBu', origin='lower')\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Relative power', fontsize = 15)\n",
    "    plt.figure(figsize=(18, 5), dpi=300)\n",
    "    plt.imshow(np.log10(np.abs(fk2d)), aspect='auto', cmap='RdBu', origin='lower')\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Relative power', fontsize = 15)\n",
    "    #######################\n",
    "    image = filt_data.real.T[:,:,np.newaxis]*200\n",
    "    image = image - np.nanmin(image)\n",
    "    denoised_image = cv2.medianBlur(image.astype(np.uint8), 7)/256\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    plt.pcolormesh(x, stretch_range-1, denoised_image, shading='auto', vmin=0.3, vmax=0.8, cmap = 'hot')\n",
    "    plt.title('median filter in 2D')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "    #######################\n",
    "#     kernel_size_x = 2\n",
    "#     denoised_image_x = np.zeros_like(denoised_image)\n",
    "#     for i in range(image.shape[1]):\n",
    "#         denoised_image_x[:, i] = np.median(image[:, i - kernel_size_x:i + kernel_size_x + 1, 0], axis=1)\n",
    "   \n",
    "#     plt.figure(figsize=(18, 5))\n",
    "#     plt.imshow(denoised_image_x, aspect = 'auto', cmap = 'hot', vmax=200, vmin=80, origin='lower')\n",
    "#     plt.title('median filter along X')\n",
    "#     plt.colorbar()\n",
    "    #######################\n",
    "    plt.figure(figsize=(18, 5))\n",
    "    dvv_ind = np.argmax(denoised_image, axis=0)\n",
    "    dvv = np.zeros(len(dvv_ind), dtype=np.float32)\n",
    "    for i in range(len(dvv_ind)):\n",
    "        dvv[i]= stretch_range[dvv_ind[i]]\n",
    "    cc_dvv = np.nanmax(denoised_image, axis=0)\n",
    "    plt.scatter(x, dvv-np.mean(dvv), cmap='viridis', c=cc_dvv, s=40, marker='o')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    plt.title('dVV after denoising')\n",
    "    plt.ylim(-0.6, 0.6)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n",
    "    \n",
    "    # Save all stretch ratio and CC\n",
    "    with h5py.File('dvv_stretch_cc_25_50Hz.hdf5', 'r') as f:\n",
    "        ratio_all = f['ratio'][:]\n",
    "        cc_all = f['cc'][:]\n",
    "    plt.figure(figsize = (18, 5))\n",
    "    plt.scatter(x, ratio_all[iloc]-np.mean(ratio_all[iloc]), cmap='viridis', c=np.array(cc_all[iloc]), s=40, marker='o')\n",
    "    plt.xticks(xax, hrax, fontsize = 10)\n",
    "    plt.title('dVV raw')\n",
    "    plt.ylim(-0.6, 0.6)\n",
    "    bar=plt.colorbar()\n",
    "    bar.set_label('Cross-correlation Coefficient', fontsize = 15)\n",
    "    plt.xlabel(\"time\", fontsize = 16)\n",
    "    plt.ylabel(\"dV / V\", fontsize = 16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880c30bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(dvv_ind)):\n",
    "    dvv[i]= stretch_range[dvv_ind[i]]\n",
    "    \n",
    "stretch_range[63]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seismo (SHARED)",
   "language": "python",
   "name": "seismo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
